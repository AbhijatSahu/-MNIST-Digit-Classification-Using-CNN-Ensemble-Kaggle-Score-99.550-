{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # Convert tensor/array to PIL image\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),  # Converts back to tensor and scales to [0,1]\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST mean & std\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X.astype(np.uint8).reshape(-1, 28, 28)  # keep as image-like array\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('digit-recognizer/train.csv')  # replace with actual path\n",
    "\n",
    "X = df.iloc[:, 1:].values  # pixels\n",
    "y = df.iloc[:, 0].values   # labels\n",
    "\n",
    "# Optional: train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = DigitDataset(X_train, y_train, transform=train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "val_dataset = DigitDataset(X_val, y_val, transform=val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),  # 28x28 → 28x28\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), # 28x28 → 28x28\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),              # 28x28 → 14x14\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),# 14x14 → 14x14\n",
    "            nn.Dropout2d(0.2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),              # 14x14 → 7x7\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 7 * 7, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 244.6045, Val Acc: 0.9829\n",
      "Epoch 2, Train Loss: 100.7971, Val Acc: 0.9867\n",
      "Epoch 3, Train Loss: 69.2830, Val Acc: 0.9893\n",
      "Epoch 4, Train Loss: 57.7086, Val Acc: 0.9917\n",
      "Epoch 5, Train Loss: 48.5856, Val Acc: 0.9919\n",
      "Epoch 6, Train Loss: 45.5581, Val Acc: 0.9926\n",
      "Epoch 7, Train Loss: 41.6774, Val Acc: 0.9931\n",
      "Epoch 8, Train Loss: 40.7047, Val Acc: 0.9926\n",
      "Epoch 9, Train Loss: 37.0766, Val Acc: 0.9929\n",
      "Epoch 10, Train Loss: 36.0120, Val Acc: 0.9931\n",
      "Epoch 11, Train Loss: 35.8690, Val Acc: 0.9931\n",
      "Epoch 12, Train Loss: 34.5244, Val Acc: 0.9929\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "model1 = CNNModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model1.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n",
    "\n",
    "patience = 5  # stop after 3 epochs without improvement\n",
    "best_val_acc = 0\n",
    "epochs_without_improvement = 0\n",
    "best_model_wts = copy.deepcopy(model1.state_dict())\n",
    "\n",
    "for epoch in range(100):  # set a higher max epoch\n",
    "    model1.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model1(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Validation step\n",
    "    model1.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model1(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {total_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_wts = copy.deepcopy(model1.state_dict())\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model1.state_dict(), \"best_model.pt\")  # save best model\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel2, self).__init__()\n",
    "\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                nn.Dropout(0.25)\n",
    "            )\n",
    "\n",
    "        self.block1 = conv_block(1, 64)     # 28x28 → 14x14\n",
    "        self.block2 = conv_block(64, 128)   # 14x14 → 7x7\n",
    "        self.block3 = conv_block(128, 256)  # 7x7 → 3x3\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # 3x3 → 1x1\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 185.5704, Val Acc: 0.9838\n",
      "Epoch 2, Train Loss: 55.6448, Val Acc: 0.9912\n",
      "Epoch 3, Train Loss: 45.7892, Val Acc: 0.9879\n",
      "Epoch 4, Train Loss: 30.6979, Val Acc: 0.9919\n",
      "Epoch 5, Train Loss: 28.1653, Val Acc: 0.9926\n",
      "Epoch 6, Train Loss: 26.3641, Val Acc: 0.9929\n",
      "Epoch 7, Train Loss: 19.0993, Val Acc: 0.9938\n",
      "Epoch 8, Train Loss: 17.3804, Val Acc: 0.9931\n",
      "Epoch 9, Train Loss: 17.9168, Val Acc: 0.9943\n",
      "Epoch 10, Train Loss: 14.1133, Val Acc: 0.9943\n",
      "Epoch 11, Train Loss: 13.6612, Val Acc: 0.9940\n",
      "Epoch 12, Train Loss: 14.2235, Val Acc: 0.9943\n",
      "Epoch 13, Train Loss: 12.4773, Val Acc: 0.9948\n",
      "Epoch 14, Train Loss: 11.7111, Val Acc: 0.9943\n",
      "Epoch 15, Train Loss: 9.9794, Val Acc: 0.9948\n",
      "Epoch 16, Train Loss: 10.6661, Val Acc: 0.9948\n",
      "Epoch 17, Train Loss: 10.1872, Val Acc: 0.9948\n",
      "Epoch 18, Train Loss: 11.0586, Val Acc: 0.9945\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "model2 = CNNModel2()\n",
    "optimizer2 = torch.optim.AdamW(model2.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler2 = torch.optim.lr_scheduler.StepLR(optimizer2, step_size=3, gamma=0.5)\n",
    "\n",
    "best_val_acc2 = 0\n",
    "epochs_without_improvement2 = 0\n",
    "best_model_wts2 = copy.deepcopy(model2.state_dict())\n",
    "\n",
    "for epoch in range(100):  # set a higher max epoch\n",
    "    model2.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer2.zero_grad()\n",
    "        outputs = model2(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler2.step()\n",
    "\n",
    "    # Validation step\n",
    "    model2.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model2(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {total_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_acc > best_val_acc2:\n",
    "        best_val_acc2 = val_acc\n",
    "        best_model_wts2 = copy.deepcopy(model2.state_dict())\n",
    "        epochs_without_improvement2 = 0\n",
    "        torch.save(model2.state_dict(), \"best_model.pt\")  # save best model\n",
    "    else:\n",
    "        epochs_without_improvement2 += 1\n",
    "        if epochs_without_improvement2 >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel3, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=2, dilation=2),  # Dilated conv\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 28x28 → 14x14\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 14x14 → 7x7\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # Output: (B, 256, 1, 1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),          # (B, 256)\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 10)     # Final classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 3] Epoch 1, Train Loss: 145.4234, Val Acc: 0.9810\n",
      "[Model 3] Epoch 2, Train Loss: 41.6911, Val Acc: 0.9857\n",
      "[Model 3] Epoch 3, Train Loss: 33.2588, Val Acc: 0.9883\n",
      "[Model 3] Epoch 4, Train Loss: 23.2935, Val Acc: 0.9926\n",
      "[Model 3] Epoch 5, Train Loss: 21.1578, Val Acc: 0.9886\n",
      "[Model 3] Epoch 6, Train Loss: 18.7398, Val Acc: 0.9848\n",
      "[Model 3] Epoch 7, Train Loss: 15.2485, Val Acc: 0.9898\n",
      "[Model 3] Epoch 8, Train Loss: 13.8384, Val Acc: 0.9924\n",
      "[Model 3] Epoch 9, Train Loss: 13.7924, Val Acc: 0.9933\n",
      "[Model 3] Epoch 10, Train Loss: 11.0826, Val Acc: 0.9940\n",
      "[Model 3] Epoch 11, Train Loss: 9.7137, Val Acc: 0.9940\n",
      "[Model 3] Epoch 12, Train Loss: 9.0619, Val Acc: 0.9931\n",
      "[Model 3] Epoch 13, Train Loss: 8.3363, Val Acc: 0.9938\n",
      "[Model 3] Epoch 14, Train Loss: 7.7449, Val Acc: 0.9940\n",
      "[Model 3] Epoch 15, Train Loss: 8.2545, Val Acc: 0.9938\n",
      "Model 3: Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "model3 = CNNModel3()\n",
    "optimizer3 = torch.optim.AdamW(model3.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler3 = torch.optim.lr_scheduler.StepLR(optimizer3, step_size=3, gamma=0.6)\n",
    "\n",
    "best_val_acc3 = 0\n",
    "epochs_without_improvement3 = 0\n",
    "best_model_wts3 = copy.deepcopy(model3.state_dict())\n",
    "\n",
    "for epoch in range(100):\n",
    "    model3.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        optimizer3.zero_grad()\n",
    "        outputs = model3(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer3.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler3.step()\n",
    "\n",
    "    model3.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model3(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_acc = correct / total\n",
    "    print(f\"[Model 3] Epoch {epoch+1}, Train Loss: {total_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc3:\n",
    "        best_val_acc3 = val_acc\n",
    "        best_model_wts3 = copy.deepcopy(model3.state_dict())\n",
    "        epochs_without_improvement3 = 0\n",
    "        torch.save(model3.state_dict(), \"best_model3.pt\")\n",
    "    else:\n",
    "        epochs_without_improvement3 += 1\n",
    "        if epochs_without_improvement3 >= patience:\n",
    "            print(\"Model 3: Early stopping triggered.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 1], Val Acc: 0.9931\n"
     ]
    }
   ],
   "source": [
    "# Load best model weights (optional)\n",
    "model1.load_state_dict(best_model_wts)\n",
    "model1.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model1(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "val_acc = correct / total\n",
    "print(f\"[Model 1], Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 2], Val Acc: 0.9948\n"
     ]
    }
   ],
   "source": [
    "# Load best model weights (optional)\n",
    "model2.load_state_dict(best_model_wts2)\n",
    "model2.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model2(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "val_acc = correct / total\n",
    "print(f\"[Model 2], Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model 3], Val Acc: 0.9940\n"
     ]
    }
   ],
   "source": [
    "# Load best model weights (optional)\n",
    "model3.load_state_dict(best_model_wts3)\n",
    "model3.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model3(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "val_acc = correct / total\n",
    "print(f\"[Model 3], Val Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model1.state_dict(), 'model1.pth')\n",
    "torch.save(model2.state_dict(), 'model2.pth')\n",
    "torch.save(model3.state_dict(), 'model3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel3(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU()\n",
       "  )\n",
       "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Dropout(p=0.4, inplace=False)\n",
       "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(torch.load('model1.pth'))\n",
    "model2.load_state_dict(torch.load('model2.pth'))\n",
    "model3.load_state_dict(torch.load('model3.pth'))\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "model3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel3(\n",
       "  (conv_layers): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU()\n",
       "  )\n",
       "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Dropout(p=0.4, inplace=False)\n",
       "    (2): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.to(device)\n",
    "model2.to(device)\n",
    "model3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 99.60%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs1 = F.softmax(model1(images), dim=1)\n",
    "        outputs2 = F.softmax(model2(images), dim=1)\n",
    "        outputs3 = F.softmax(model3(images), dim=1)\n",
    "\n",
    "        avg_output = (outputs1 + outputs2 + outputs3) / 3\n",
    "        _, preds = torch.max(avg_output, 1)\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "val_acc = correct / total\n",
    "\n",
    "print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, X, transform=None):\n",
    "        self.X = X.astype(np.uint8).reshape(-1, 28, 28)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('digit-recognizer/test.csv')  # shape: (28000, 784)\n",
    "X_test = df_test.values  # numpy array of shape (28000, 784)\n",
    "\n",
    "test_dataset = TestDataset(X_test, transform=val_transform)  # use val_transform (no augmentation)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "\n",
    "        outputs1 = F.softmax(model1(images), dim=1)\n",
    "        outputs2 = F.softmax(model2(images), dim=1)\n",
    "        outputs3 = F.softmax(model3(images), dim=1)\n",
    "\n",
    "        avg_output = (outputs1 + outputs2 + outputs3) / 3\n",
    "        _, preds = torch.max(avg_output, 1)\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'ImageId': np.arange(1, len(predictions) + 1),\n",
    "    'Label': predictions\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
